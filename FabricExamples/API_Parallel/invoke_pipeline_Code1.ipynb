{"cells":[{"cell_type":"code","source":["import requests\n","from synapse.ml.fabric import FabricCredential\n"," \n","token = FabricCredential().get_token()\n","headers = dict()\n","headers['Authorization'] = f'Bearer {token.token}'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"livy_statement_state":"available","session_id":"f09da00e-4c95-4ea9-be24-e79b4b8c4f4f","state":"finished","normalized_state":"finished","queued_time":"2024-06-26T12:27:04.4120889Z","session_start_time":"2024-06-26T12:27:04.7925497Z","execution_start_time":"2024-06-26T12:30:02.2407918Z","execution_finish_time":"2024-06-26T12:30:05.5722903Z","parent_msg_id":"39629eef-58cd-4bd0-acd6-68d762826a8d"},"text/plain":"StatementMeta(, f09da00e-4c95-4ea9-be24-e79b4b8c4f4f, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dc790c97-3ab5-427b-b661-2b6862cd7313"},{"cell_type":"markdown","source":["#### Invoke and monitor pipeline execution"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7846b0f4-2f66-4de6-9baa-e648b0a3162e"},{"cell_type":"code","source":["import requests\n","from urllib.parse import urlparse\n","import time\n","import json\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","# Replace with your workspace and pipeline identifiers\n","workspace = \"\"\n","pipeline = \" \"\n","\n","url = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace}/items/{pipeline}/jobs/instances?jobType=Pipeline\"\n","\n","payload = {\n","    \"executionData\": {}\n","}\n","\n","\n","def execute_pipeline():\n","\n","    response = requests.post(url, json=payload, headers=headers)\n","    response.raise_for_status()\n","\n","    if response.status_code in [200, 202]:\n","        location_header = response.headers.get(\"Location\")\n","        parsed_url = urlparse(location_header)\n","        path_parts = parsed_url.path.split('/')\n","        job_instance_id = path_parts[-1]\n","\n","        url_get = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace}/items/{pipeline}/jobs/instances/{job_instance_id}\"\n","\n","        while True:\n","            # Make the GET request\n","            response_status = requests.get(url_get, headers=headers)\n","\n","            if response_status.status_code == 200:\n","                try:\n","                    response_data = response_status.json()\n","                    status = response_data.get('status')\n","\n","                    if status == 'Completed':\n","                        print(\"Status:\", status)\n","                        break  # Exit the loop if status is \"Completed\"\n","                    else:\n","                        print(\"Execution is still in progress. Checking again...\")\n","                        print(\"Status:\", status)\n","                except json.JSONDecodeError:\n","                    print(\"JSON Decode Error. Retrying...\")\n","\n","            else:\n","                print('Error:', response_status.status_code)\n","                break\n","\n","            time.sleep(20)\n","\n","def main():\n","    with ThreadPoolExecutor(max_workers=15) as executor:\n","        futures = [executor.submit(execute_pipeline) for _ in range(15)]\n","\n","        for future in as_completed(futures):\n","            try:\n","                future.result()\n","            except Exception as e:\n","                print(f\"Pipeline execution generated an exception: {e}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"286ed3fa-b0a6-4e53-a03e-3acf4ff3ceae"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"51ae4f4e-82d6-4408-82d8-da1413bfc7e9","default_lakehouse_name":"API","default_lakehouse_workspace_id":"4be314f7-a05d-4043-bbc9-0dbf7decff5c"}}},"nbformat":4,"nbformat_minor":5}